{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport zipfile\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom torchvision import transforms\nfrom torchvision.models import resnet50\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import f1_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image, ImageFilter, ImageEnhance\nfrom tqdm import tqdm\nfrom torch.cuda.amp import autocast, GradScaler\n\n# --- 0. Setup Kaggle and Data ---\nos.environ['KAGGLE_USERNAME'] = 'shivam790'\nos.environ['KAGGLE_KEY'] = '382c7bf4cacced2e14d0360737efc6c9'\n\nif not os.path.exists(\"soil-classification-part-2.zip\"):\n    os.system(\"kaggle competitions download -c soil-classification-part-2\")\n\nif not os.path.exists(\"soil_competition-2025\"):\n    with zipfile.ZipFile(\"soil-classification-part-2.zip\", 'r') as zip_ref:\n        zip_ref.extractall(\"soil_competition-2025\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T23:11:10.020225Z","iopub.execute_input":"2025-05-24T23:11:10.020530Z","iopub.status.idle":"2025-05-24T23:11:26.870378Z","shell.execute_reply.started":"2025-05-24T23:11:10.020498Z","shell.execute_reply":"2025-05-24T23:11:26.869420Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.svm import OneClassSVM\nfrom sklearn.preprocessing import StandardScaler\nfrom tqdm import tqdm\nimport numpy as np\nimport timm  # For DINOv2\n\n# --- Paths ---\ntrain_csv = \"/kaggle/working/soil_competition-2025/soil_competition-2025/train_labels.csv\"\ntrain_dir = \"/kaggle/working/soil_competition-2025/soil_competition-2025/train\"\ntest_csv = \"/kaggle/working/soil_competition-2025/soil_competition-2025/test_ids.csv\"\ntest_dir = \"/kaggle/working/soil_competition-2025/soil_competition-2025/test\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# --- Load DINOv2 model ---\nmodel = timm.create_model(\"vit_base_patch16_224.dino\", pretrained=True)\nmodel.head = torch.nn.Identity()\nmodel.eval().to(DEVICE)\n\n# --- Image preprocessing ---\nfrom torchvision import transforms\nimage_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\n# --- Dataset Class ---\nclass ImageDataset(Dataset):\n    def __init__(self, df, image_dir, transform):\n        self.df = df\n        self.image_dir = image_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image_id = self.df.iloc[idx]['image_id']\n        img_path = os.path.join(self.image_dir, image_id)\n        image = Image.open(img_path).convert(\"RGB\")\n        image = self.transform(image)\n        return image, image_id\n\n# --- Extract embeddings ---\ndef extract_embeddings(loader):\n    all_embeddings = []\n    all_ids = []\n    with torch.no_grad():\n        for images, ids in tqdm(loader, desc=\"Extracting embeddings\"):\n            images = images.to(DEVICE)\n            feats = model(images)\n            all_embeddings.append(feats.cpu().numpy())\n            all_ids.extend(ids)\n    return np.vstack(all_embeddings), all_ids\n\n# --- Train loader ---\ndf_train = pd.read_csv(train_csv)\ntrain_dataset = ImageDataset(df_train, train_dir, image_transform)\ntrain_loader = DataLoader(train_dataset, batch_size=32)\n\ntrain_feats, _ = extract_embeddings(train_loader)\n\n# --- Normalize & Train One-Class SVM ---\nscaler = StandardScaler()\ntrain_feats_scaled = scaler.fit_transform(train_feats)\n\nsvm = OneClassSVM(kernel='rbf', nu=0.05, gamma='scale')\nsvm.fit(train_feats_scaled)\n\n# --- Test loader ---\ndf_test = pd.read_csv(test_csv)\ntest_dataset = ImageDataset(df_test, test_dir, image_transform)\ntest_loader = DataLoader(test_dataset, batch_size=32)\n\ntest_feats, test_ids = extract_embeddings(test_loader)\ntest_feats_scaled = scaler.transform(test_feats)\n\npreds = svm.predict(test_feats_scaled)\n\n# +1 = soil (inlier), -1 = not soil (outlier)\nresults = [{\"image_id\": img_id, \"label\": 1 if pred == 1 else 0} for img_id, pred in zip(test_ids, preds)]\n\n# --- Save Submission ---\ndf_out = pd.DataFrame(results)\ndf_out.to_csv(\"submission.csv\", index=False)\nprint(\"✅ submission.csv saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T23:14:24.193742Z","iopub.execute_input":"2025-05-24T23:14:24.194157Z","iopub.status.idle":"2025-05-24T23:27:12.418537Z","shell.execute_reply.started":"2025-05-24T23:14:24.194125Z","shell.execute_reply":"2025-05-24T23:27:12.417067Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/343M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d625d913d76f417c98a68d188e069a0f"}},"metadata":{}},{"name":"stderr","text":"Extracting embeddings: 100%|██████████| 39/39 [07:26<00:00, 11.44s/it]\nExtracting embeddings: 100%|██████████| 31/31 [05:11<00:00, 10.06s/it]","output_type":"stream"},{"name":"stdout","text":"✅ submission.csv saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}